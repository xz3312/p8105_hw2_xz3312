---
title: "p8105_hw2_xz3312"
author: "Eric Zhang"
date: "2025-09-26"
output: github_document
---

```{r}
library(tidyverse)
library(readxl)
library(haven)
```
#Problem 1
##Let's import the dataset pols_month and make changes to it [problem 1 part 1]
```{r}
pols_month_df = 
  read.csv("fivethirtyeight_datasets/pols-month.csv", na=c("NA",".",""))

library(dplyr)
library(tidyr)

pols_month_clean_df = 
  read.csv("fivethirtyeight_datasets/pols-month.csv", na=c("NA",".","")) %>% 
  as_tibble() %>% 
  separate(mon, into = c("year", "month", "day"), sep = "-", convert = TRUE) %>% 
  mutate(
    month = factor(month.name[month], levels = month.name),
    president = if_else(prez_gop == 1, "gop", "dem")
  ) %>% 
  select(-prez_dem, -prez_gop)
```

##Let's import the dataset snp.csv and make similar changes to it [problem 1 part 2]
```{r}
snp_df =
  read.csv("fivethirtyeight_datasets/snp.csv", na=c("NA",".",""))

library(dplyr)
library(tidyr)

snp_clean_df =
    read.csv("fivethirtyeight_datasets/snp.csv", na=c("NA",".","")) %>%
  as_tibble() %>% 
  separate(date, into = c("month","day","year"), sep = "/", convert = TRUE) %>% 
  mutate(
    year = year + if_else(year>=50L, 1900L,2000L),
    month = factor(month.name[month], levels = month.name)
  ) %>% 
  relocate(year, month, day)
      
```

##Let's import and tidy the unemployment dataset so it can be merged with previous datasets [problem 1 part 3]
```{r}
unemployment_df =
   read.csv("fivethirtyeight_datasets/unemployment.csv", na=c("NA",".",""))

library(dplyr)
library(tidyr)
library(janitor)
library(stringr)

unemployment_clean_df <-
  read.csv("fivethirtyeight_datasets/unemployment.csv",
           na = c("NA", ".", "")) %>%
  as_tibble() %>%
  clean_names() %>%
  pivot_longer(
    cols = jan:dec,              # after clean_names(): jan, feb, ..., dec
    names_to = "month",
    values_to = "unemployment_percentage"
  ) %>%
  mutate(
    month = factor(
      str_to_title(month),       # "jan" -> "Jan"
      levels = month.abb,        # "Jan","Feb",...,"Dec"
      ordered = TRUE
    )
  ) %>%
  arrange(year, month)

pols2  <- pols_month_clean_df  %>% mutate(month = str_to_title(as.character(month)))
snp2   <- snp_clean_df         %>% mutate(month = str_to_title(as.character(month)))
unemp2 <- unemployment_clean_df %>% mutate(month = str_to_title(as.character(month)))

merged_df <- pols2 %>%
  left_join(snp2,  by = c("year", "month")) %>%
  left_join(unemp2, by = c("year", "month"))

```
The `pols_month_clean_df` dataset gives information about the composition of the U.S. executive and legislative branches by month and year, and which party holds the office. The `snp_clean_df` dataset contains monthly closing values of the stock market, connecting politics to market performance. The `unemployment_clean_df` dataset reports unemployment percentages by month and year and contains `r nrow(unemployment_clean_df)` total monthly observations. After cleaning, these three datasets were merged to create a single data frame `merged_df` with `r nrow(merged_df)` rows and `r ncol(merged_df)` columns. The merged data set covers `r min(merged_df$year)` and includes variables such as `year`, `month`, `president`, `close`, and `unemployment_percentage`. I wish the unemployment dataset provided day of month information, this extra detail would reduce the number of `NA` values in the dataset.


#Problem 2
```{r}
library(readxl)
library(dplyr)
library(janitor)
library(lubridate)
mrtrashwheel_df = 
  read_excel("~/Desktop/p8105_homework_2/202409_trashwheel.xlsx", na=c("NA",".",""))


mrtrashwheel_df <- mrtrashwheel_df %>%  clean_names()

mrtrashwheel_clean_df <- mrtrashwheel_df %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(
    date = as.Date(as.character(date)),
    sports_balls = as.integer(round(sports_balls))
  )


mrtrashwheel_clean_df %>% 
  select(-x15,-x16)

```
##Do the same for professor trashwheel and gwynnda trashwheel data
```{r}
library(readxl)
library(dplyr)
library(janitor)
prof_trashwheel_df <- read_excel(
  path  = "~/Desktop/p8105_homework_2/202409_trashwheel.xlsx",
  sheet = "Professor Trash Wheel",   
  skip  = 1,                         
  na    = c("", "NA", "."),
) 


proftrashwheel_clean_df <- prof_trashwheel_df %>%
  mutate(
    `Homes Powered*` = as.integer(round(`Homes Powered*`)) 
  )

proftrashwheel_clean_df <- proftrashwheel_clean_df[-c(119, 120, 121), ] #I noticed row 119 to 121 had mostly NA values, so I removed them


gwynnda_trashwheel_df <- read_excel(
  path  = "~/Desktop/p8105_homework_2/202409_trashwheel.xlsx",
  sheet = "Gwynnda Trash Wheel",   
  skip  = 1,                         
  na    = c("", "NA", "."),
) 

gwynndatrashwheel_clean_df <- gwynnda_trashwheel_df %>% 
  mutate(
    `Homes Powered*` = as.integer(round(`Homes Powered*`)) #rounded home powered to integer
  )


gwynndatrashwheel_clean_df <- gwynndatrashwheel_clean_df[-c(264), ] #removed row 264 which is NA

proftrashwheel_clean_df   <- proftrashwheel_clean_df   %>% clean_names()
gwynndatrashwheel_clean_df <- gwynndatrashwheel_clean_df %>% clean_names() #make column names all non-capitalized in order to combine them

library(dplyr)
library(purrr)


num_cols <- c(
  "weight_tons","volume_cubic_yards","plastic_bottles","polystyrene",
  "cigarette_butts","glass_bottles","plastic_bags","wrappers",
  "sports_balls","homes_powered"
)


coerce_types <- function(df) {
  df %>%
    mutate(
      year  = as.integer(year),
      month = as.character(month),
      date  = as.Date(date)
    ) %>%
    mutate(across(any_of(num_cols), as.numeric))
}

trashwheel_all <- list(
  mrtrashwheel_clean_df   %>% mutate(wheel = "Mr"),
  proftrashwheel_clean_df %>% mutate(wheel = "Professor"),
  gwynndatrashwheel_clean_df %>% mutate(wheel = "Gwynnda")
) %>%
  map(coerce_types) %>%
  bind_rows() %>%
  select(wheel, everything())


trashwheel_all %>%
  filter(wheel == "Professor") %>%
  summarise(total_weight_tons = sum(weight_tons, na.rm = TRUE))

trashwheel_all %>%
  filter(wheel == "Gwynnda", year == 2022, month == "June") %>%
  summarise(total_cigarette_butts = sum(cigarette_butts, na.rm = TRUE))




```

The combined `trashwheel_all` dataset contains `r nrow(trashwheel_all)` observations of `r ncol(trashwheel_all)` variables from three datasets, each representing one dumpster’s collection event from Mr. Trash Wheel, Professor Trash Wheel, or Gwynnda. Important variables include `date` (the collection date), `weight_tons` (tons of trash removed), and specific counts such as `cigarette_butts`, `plastic_bottles`, and `sports_balls`. The total weight in tons collected by Professor Trash Wheel is `r trashwheel_all %>% filter(wheel == "Professor") %>% summarise(sum(weight_tons, na.rm = TRUE)) %>% pull()`, and the total number of cigarette butts collected by Gwynnda in June 2022 is `r trashwheel_all %>% filter(wheel == "Gwynnda", year == 2022, month == "June") %>% summarise(sum(cigarette_butts, na.rm = TRUE)) %>% pull()`.



#Problem 3 with updated dataset

```{r}
## Problem 3 ----
library(readr)
library(dplyr)
library(tidyr)
library(stringr)
library(lubridate)
library(janitor)


zip <-
  read_csv("zillow_data/Zip Codes.csv", na = c("NA", "")) %>%
  clean_names()

price_raw <-
  read_csv("zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv", na = c("NA", "")) %>%
  clean_names()

date_cols <- names(price_raw)[grepl("^x?\\d{4}_\\d{2}_\\d{2}$", names(price_raw))]

price <-
  price_raw %>%
  mutate(county_name = str_remove(county_name, " County$")) %>%
  rename_with(~ str_remove(.x, "^x"), .cols = all_of(date_cols)) %>%
  rename(
    zip_code = region_name,
    county   = county_name
  ) %>%
  drop_na(all_of(str_remove(date_cols, "^x"))) %>%
  select(-any_of(c("region_type", "state_name")))

joint_data <-
  right_join(zip, price, by = c("zip_code", "county")) %>%
  pivot_longer(
    cols = matches("^\\d{4}_\\d{2}_\\d{2}$"),
    names_to  = "date",
    values_to = "price"
  ) %>%
  mutate(
    date = ymd(date),
    borough = dplyr::recode(
      county,
      "Bronx"    = "Bronx",
      "Kings"    = "Brooklyn",
      "New York" = "Manhattan",
      "Queens"   = "Queens",
      "Richmond" = "Staten Island",
      .default   = NA_character_
    )
  ) %>%
  select(
    state, city, county, borough, state_fips, county_fips, county_code,
    metro, neighborhood, zip_code, region_id, size_rank, date, price, file_date
  ) %>%
  arrange(zip_code, date)


n_obs        <- nrow(joint_data)
n_zip_unique <- n_distinct(joint_data$zip_code)
n_nbhd       <- n_distinct(joint_data$neighborhood)

n_obs; n_zip_unique; n_nbhd


zips_missing <-
  zip %>%
  filter(!zip_code %in% price$zip_code) %>%
  arrange(county, neighborhood, zip_code)

head(zips_missing, 10)

jan_2020 <- joint_data %>%
  filter(date == ymd("2020-01-31")) %>%
  select(zip_code, price_2020 = price)

jan_2021 <- joint_data %>%
  filter(date == ymd("2021-01-31")) %>%
  select(zip_code, price_2021 = price)

largest10_drop <-
  jan_2020 %>%
  inner_join(jan_2021, by = "zip_code") %>%
  mutate(
    change     = price_2021 - price_2020,
    pct_change = 100 * change / price_2020
  ) %>%
  left_join(
    zip %>% select(zip_code, neighborhood, county),
    by = "zip_code"
  ) %>%
  mutate(
    borough = dplyr::recode(
      county,
      "Bronx"    = "Bronx",
      "Kings"    = "Brooklyn",
      "New York" = "Manhattan",
      "Queens"   = "Queens",
      "Richmond" = "Staten Island",
      .default   = NA_character_
    )
  ) %>%
  arrange(change) %>%
  slice_head(n = 10) %>%
  select(zip_code, borough, neighborhood, county,
         price_2020, price_2021, change, pct_change)

largest10_drop

```
After importing and cleaning the updated files, I created a single tidy dataset (joint_data) spanning r format(min(joint_data$date), "%Y-%m")–r format(max(joint_data$date), "%Y-%m"), with r n_obs monthly observations across r n_zip_unique unique ZIP codes and r n_nbhd neighborhoods. Key variables are zip_code, date, and price (ZORI), along with location metadata such as borough, county, and neighborhood. ZIP codes found in the crosswalk but missing from the Zillow rental dataset (zips_missing) are likely non-residential or suppressed ZIPs. Comparing January 2020 to January 2021, the table largest10_drop reports the 10 ZIP codes with the largest rent declines, with their borough and neighborhood.
