p8105_hw2_xz3312
================
Eric Zhang
2025-09-26

``` r
library(tidyverse)
```

    ## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──
    ## ✔ dplyr     1.1.4     ✔ readr     2.1.5
    ## ✔ forcats   1.0.0     ✔ stringr   1.5.1
    ## ✔ ggplot2   3.5.2     ✔ tibble    3.3.0
    ## ✔ lubridate 1.9.4     ✔ tidyr     1.3.1
    ## ✔ purrr     1.1.0     
    ## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──
    ## ✖ dplyr::filter() masks stats::filter()
    ## ✖ dplyr::lag()    masks stats::lag()
    ## ℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors

``` r
library(readxl)
library(haven)
```

\#Problem 1 \##Let’s import the dataset pols_month and make changes to
it \[problem 1 part 1\]

``` r
pols_month_df = 
  read.csv("fivethirtyeight_datasets/pols-month.csv", na=c("NA",".",""))

library(dplyr)
library(tidyr)

pols_month_clean_df = 
  read.csv("fivethirtyeight_datasets/pols-month.csv", na=c("NA",".","")) %>% 
  as_tibble() %>% 
  separate(mon, into = c("year", "month", "day"), sep = "-", convert = TRUE) %>% 
  mutate(
    month = factor(month.name[month], levels = month.name),
    president = if_else(prez_gop == 1, "gop", "dem")
  ) %>% 
  select(-prez_dem, -prez_gop)
```

\##Let’s import the dataset snp.csv and make similar changes to it
\[problem 1 part 2\]

``` r
snp_df =
  read.csv("fivethirtyeight_datasets/snp.csv", na=c("NA",".",""))

library(dplyr)
library(tidyr)

snp_clean_df =
    read.csv("fivethirtyeight_datasets/snp.csv", na=c("NA",".","")) %>%
  as_tibble() %>% 
  separate(date, into = c("month","day","year"), sep = "/", convert = TRUE) %>% 
  mutate(
    year = year + if_else(year>=50L, 1900L,2000L),
    month = factor(month.name[month], levels = month.name)
  ) %>% 
  relocate(year, month, day)
```

\##Let’s import and tidy the unemployment dataset so it can be merged
with previous datasets \[problem 1 part 3\]

``` r
unemployment_df =
   read.csv("fivethirtyeight_datasets/unemployment.csv", na=c("NA",".",""))

library(dplyr)
library(tidyr)
library(janitor)
```

    ## 
    ## Attaching package: 'janitor'

    ## The following objects are masked from 'package:stats':
    ## 
    ##     chisq.test, fisher.test

``` r
library(stringr)

unemployment_clean_df <-
  read.csv("fivethirtyeight_datasets/unemployment.csv",
           na = c("NA", ".", "")) %>%
  as_tibble() %>%
  clean_names() %>%
  pivot_longer(
    cols = jan:dec,              # after clean_names(): jan, feb, ..., dec
    names_to = "month",
    values_to = "unemployment_percentage"
  ) %>%
  mutate(
    month = factor(
      str_to_title(month),       # "jan" -> "Jan"
      levels = month.abb,        # "Jan","Feb",...,"Dec"
      ordered = TRUE
    )
  ) %>%
  arrange(year, month)

pols2  <- pols_month_clean_df  %>% mutate(month = str_to_title(as.character(month)))
snp2   <- snp_clean_df         %>% mutate(month = str_to_title(as.character(month)))
unemp2 <- unemployment_clean_df %>% mutate(month = str_to_title(as.character(month)))

merged_df <- pols2 %>%
  left_join(snp2,  by = c("year", "month")) %>%
  left_join(unemp2, by = c("year", "month"))
```

The `pols_month_clean_df` dataset gives information about the
composition of the U.S. executive and legislative branches by month and
year, and which party holds the office. The `snp_clean_df` dataset
contains monthly closing values of the stock market, connecting politics
to market performance. The `unemployment_clean_df` dataset reports
unemployment percentages by month and year and contains 816 total
monthly observations. After cleaning, these three datasets were merged
to create a single data frame `merged_df` with 822 rows and 13 columns.
The merged data set covers 1947 and includes variables such as `year`,
`month`, `president`, `close`, and `unemployment_percentage`. I wish the
unemployment dataset provided day of month information, this extra
detail would reduce the number of `NA` values in the dataset.

\#Problem 2

``` r
library(readxl)
library(dplyr)
library(janitor)
library(lubridate)
mrtrashwheel_df = 
  read_excel("~/Desktop/p8105_homework_2/202409_trashwheel.xlsx", na=c("NA",".",""))
```

    ## New names:
    ## • `` -> `...15`
    ## • `` -> `...16`

``` r
mrtrashwheel_df <- mrtrashwheel_df %>%  clean_names()

mrtrashwheel_clean_df <- mrtrashwheel_df %>% 
  filter(!is.na(dumpster)) %>% 
  mutate(
    date = as.Date(as.character(date)),
    sports_balls = as.integer(round(sports_balls))
  )


mrtrashwheel_clean_df %>% 
  select(-x15,-x16)
```

    ## # A tibble: 651 × 14
    ##    dumpster month year  date       weight_tons volume_cubic_yards
    ##       <dbl> <chr> <chr> <date>           <dbl>              <dbl>
    ##  1        1 May   2014  2014-05-16        4.31                 18
    ##  2        2 May   2014  2014-05-16        2.74                 13
    ##  3        3 May   2014  2014-05-16        3.45                 15
    ##  4        4 May   2014  2014-05-17        3.1                  15
    ##  5        5 May   2014  2014-05-17        4.06                 18
    ##  6        6 May   2014  2014-05-20        2.71                 13
    ##  7        7 May   2014  2014-05-21        1.91                  8
    ##  8        8 May   2014  2014-05-28        3.7                  16
    ##  9        9 June  2014  2014-06-05        2.52                 14
    ## 10       10 June  2014  2014-06-11        3.76                 18
    ## # ℹ 641 more rows
    ## # ℹ 8 more variables: plastic_bottles <dbl>, polystyrene <dbl>,
    ## #   cigarette_butts <dbl>, glass_bottles <dbl>, plastic_bags <dbl>,
    ## #   wrappers <dbl>, sports_balls <int>, homes_powered <dbl>

\##Do the same for professor trashwheel and gwynnda trashwheel data

``` r
library(readxl)
library(dplyr)
library(janitor)
prof_trashwheel_df <- read_excel(
  path  = "~/Desktop/p8105_homework_2/202409_trashwheel.xlsx",
  sheet = "Professor Trash Wheel",   
  skip  = 1,                         
  na    = c("", "NA", "."),
) 


proftrashwheel_clean_df <- prof_trashwheel_df %>%
  mutate(
    `Homes Powered*` = as.integer(round(`Homes Powered*`)) 
  )

proftrashwheel_clean_df <- proftrashwheel_clean_df[-c(119, 120, 121), ] #I noticed row 119 to 121 had mostly NA values, so I removed them


gwynnda_trashwheel_df <- read_excel(
  path  = "~/Desktop/p8105_homework_2/202409_trashwheel.xlsx",
  sheet = "Gwynnda Trash Wheel",   
  skip  = 1,                         
  na    = c("", "NA", "."),
) 

gwynndatrashwheel_clean_df <- gwynnda_trashwheel_df %>% 
  mutate(
    `Homes Powered*` = as.integer(round(`Homes Powered*`)) #rounded home powered to integer
  )


gwynndatrashwheel_clean_df <- gwynndatrashwheel_clean_df[-c(264), ] #removed row 264 which is NA

proftrashwheel_clean_df   <- proftrashwheel_clean_df   %>% clean_names()
gwynndatrashwheel_clean_df <- gwynndatrashwheel_clean_df %>% clean_names() #make column names all non-capitalized in order to combine them

library(dplyr)
library(purrr)


num_cols <- c(
  "weight_tons","volume_cubic_yards","plastic_bottles","polystyrene",
  "cigarette_butts","glass_bottles","plastic_bags","wrappers",
  "sports_balls","homes_powered"
)


coerce_types <- function(df) {
  df %>%
    mutate(
      year  = as.integer(year),
      month = as.character(month),
      date  = as.Date(date)
    ) %>%
    mutate(across(any_of(num_cols), as.numeric))
}

trashwheel_all <- list(
  mrtrashwheel_clean_df   %>% mutate(wheel = "Mr"),
  proftrashwheel_clean_df %>% mutate(wheel = "Professor"),
  gwynndatrashwheel_clean_df %>% mutate(wheel = "Gwynnda")
) %>%
  map(coerce_types) %>%
  bind_rows() %>%
  select(wheel, everything())


trashwheel_all %>%
  filter(wheel == "Professor") %>%
  summarise(total_weight_tons = sum(weight_tons, na.rm = TRUE))
```

    ## # A tibble: 1 × 1
    ##   total_weight_tons
    ##               <dbl>
    ## 1              247.

``` r
trashwheel_all %>%
  filter(wheel == "Gwynnda", year == 2022, month == "June") %>%
  summarise(total_cigarette_butts = sum(cigarette_butts, na.rm = TRUE))
```

    ## # A tibble: 1 × 1
    ##   total_cigarette_butts
    ##                   <dbl>
    ## 1                 18120

The combined `trashwheel_all` dataset contains 1032 observations of 17
variables from three datasets, each representing one dumpster’s
collection event from Mr. Trash Wheel, Professor Trash Wheel, or
Gwynnda. Important variables include `date` (the collection date),
`weight_tons` (tons of trash removed), and specific counts such as
`cigarette_butts`, `plastic_bottles`, and `sports_balls`. The total
weight in tons collected by Professor Trash Wheel is 246.74, and the
total number of cigarette butts collected by Gwynnda in June 2022 is
1.812^{4}.

\#Problem 3

``` r
## Problem 3 ----
library(readr)
library(dplyr)
library(tidyr)
library(stringr)
library(lubridate)
library(janitor)


zip <-
  read_csv("zillow_data/Zip Codes.csv", na = "NA") %>% 
  clean_names()
```

    ## Rows: 322 Columns: 7
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr (4): County, County Code, File Date, Neighborhood
    ## dbl (3): State FIPS, County FIPS, ZipCode
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
price <-
  read_csv("zillow_data/Zip_zori_uc_sfrcondomfr_sm_month_NYC.csv", na = "NA") %>% 
  clean_names() %>% 
  mutate(county_name = str_remove(county_name, " County$")) %>% 
  rename_with(~ str_remove(.x, "^x"), .cols = "x2015_01_31":"x2024_08_31") %>% 
  rename(
    zip_code = region_name,
    county   = county_name
  ) %>% 

  drop_na(`2015_01_31`:`2024_08_31`) %>% 
  select(-region_type, -state_name)
```

    ## Rows: 149 Columns: 125
    ## ── Column specification ────────────────────────────────────────────────────────
    ## Delimiter: ","
    ## chr   (6): RegionType, StateName, State, City, Metro, CountyName
    ## dbl (119): RegionID, SizeRank, RegionName, 2015-01-31, 2015-02-28, 2015-03-3...
    ## 
    ## ℹ Use `spec()` to retrieve the full column specification for this data.
    ## ℹ Specify the column types or set `show_col_types = FALSE` to quiet this message.

``` r
joint_data <-
  right_join(zip, price, by = c("zip_code", "county")) %>% 
  pivot_longer(
    `2015_01_31`:`2024_08_31`,
    names_to  = "date",
    values_to = "price"
  ) %>% 
  mutate(
    date = lubridate::ymd(date),
    borough = dplyr::recode(
      county,
      "Bronx"    = "Bronx",
      "Kings"    = "Brooklyn",
      "New York" = "Manhattan",
      "Queens"   = "Queens",
      "Richmond" = "Staten Island",
      .default   = NA_character_
    )
  ) %>% 
  select(
    state, city, county, borough, state_fips, county_fips, county_code,
    metro, neighborhood, zip_code, region_id, size_rank, date, price, file_date
  ) %>% 
  arrange(zip_code, date)


n_obs        <- nrow(joint_data)
n_zip_unique <- n_distinct(joint_data$zip_code)
n_nbhd       <- n_distinct(joint_data$neighborhood)

n_obs; n_zip_unique; n_nbhd
```

    ## [1] 5568

    ## [1] 48

    ## [1] 20

``` r
zips_missing <-
  zip %>% 
  filter(!zip_code %in% price$zip_code) %>% 
  arrange(county, neighborhood, zip_code)

head(zips_missing, 10)
```

    ## # A tibble: 10 × 7
    ##    county state_fips county_code county_fips zip_code file_date neighborhood    
    ##    <chr>       <dbl> <chr>             <dbl>    <dbl> <chr>     <chr>           
    ##  1 Bronx          36 005               36005    10458 7/25/07   Bronx Park and …
    ##  2 Bronx          36 005               36005    10467 7/25/07   Bronx Park and …
    ##  3 Bronx          36 005               36005    10468 7/25/07   Bronx Park and …
    ##  4 Bronx          36 005               36005    10453 7/25/07   Central Bronx   
    ##  5 Bronx          36 005               36005    10457 7/25/07   Central Bronx   
    ##  6 Bronx          36 005               36005    10460 7/25/07   Central Bronx   
    ##  7 Bronx          36 005               36005    10451 7/25/07   High Bridge and…
    ##  8 Bronx          36 005               36005    10452 7/25/07   High Bridge and…
    ##  9 Bronx          36 005               36005    10456 7/25/07   High Bridge and…
    ## 10 Bronx          36 005               36005    10454 7/25/07   Hunts Point and…

``` r
library(dplyr)
library(lubridate)


jan_2020 <- joint_data %>%
  filter(date == ymd("2020-01-31")) %>%
  select(zip_code, price_2020 = price)

jan_2021 <- joint_data %>%
  filter(date == ymd("2021-01-31")) %>%
  select(zip_code, price_2021 = price)

largest10_drop <-
  jan_2020 %>%
  inner_join(jan_2021, by = "zip_code") %>%
  mutate(
    change     = price_2021 - price_2020,
    pct_change = 100 * change / price_2020
  ) %>%

  left_join(zip %>% select(zip_code, neighborhood, county), by = "zip_code") %>%
  mutate(
    borough = dplyr::recode(
      county,
      "Bronx"    = "Bronx",
      "Kings"    = "Brooklyn",
      "New York" = "Manhattan",
      "Queens"   = "Queens",
      "Richmond" = "Staten Island",
      .default   = NA_character_
    )
  ) %>%
  arrange(change) %>%
  slice_head(n = 10) %>%
  select(zip_code, borough, neighborhood, county,
         price_2020, price_2021, change, pct_change)

largest10_drop
```

    ## # A tibble: 10 × 8
    ##    zip_code borough  neighborhood county price_2020 price_2021 change pct_change
    ##       <dbl> <chr>    <chr>        <chr>       <dbl>      <dbl>  <dbl>      <dbl>
    ##  1    10001 Manhatt… Chelsea and… New Y…      4108.      3398.  -710.      -17.3
    ##  2    10002 Manhatt… Lower East … New Y…      3645.      2935.  -710.      -19.5
    ##  3    10038 Manhatt… Lower Manha… New Y…      3573.      2876.  -698.      -19.5
    ##  4    10012 Manhatt… Greenwich V… New Y…      3629.      2942.  -686.      -18.9
    ##  5    10010 Manhatt… Gramercy Pa… New Y…      3697.      3012.  -685.      -18.5
    ##  6    10003 Manhatt… Lower East … New Y…      3570.      2897.  -673.      -18.8
    ##  7    10013 Manhatt… Greenwich V… New Y…      4432.      3798.  -634.      -14.3
    ##  8    10036 Manhatt… Chelsea and… New Y…      3450.      2824.  -627.      -18.2
    ##  9    10022 Manhatt… Gramercy Pa… New Y…      3471.      2853.  -619.      -17.8
    ## 10    10014 Manhatt… Greenwich V… New Y…      3768.      3188.  -580.      -15.4

After importing and cleaning both files, I created a single tidy dataset
(`joint_data`) with 5568 monthly observations across 48 unique ZIP codes
and 20 unique neighborhoods. Key variables are `zip_code`, `date`, and
`price` (ZORI), with location metadata such as `borough`, `county`, and
`neighborhood`. ZIP codes in the ZIP file but not in the Zillow rental
dataset (`zips_missing`) are likely non-residential zip codes, so Zillow
did not publish an index. Comparing January 2020 to January 2021, the
table `largest10_drop` shows the 10 ZIP codes with the largest rent
declines, along with their borough and neighborhood.
